{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Extract_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-fbRtPFv0ig",
        "outputId": "50a761ef-693e-4b90-cc78-059a89398f7e"
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 10.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 12.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 13.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/2d/804332ee1eaf36c8be737e9c44da2f2aa449339c220a96b9a15ae7f61443/boto3-1.17.69-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 33.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.1+cu101)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.69\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/bb/06710dce8770adf852785785df7e15fc1363596b712766898b1c529e358e/botocore-1.20.69-py2.py3-none-any.whl (7.5MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5MB 32.9MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.69->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.69->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.69 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.17.69 botocore-1.20.69 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5T9mCADv1F2",
        "outputId": "8569c995-2d60-4a49-a3b3-4c3ee1f248b9"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/72/d06017379ad4760dc58781c765376ce4ba5dcf3c08d37032eeefbccf1c51/tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 33kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.12.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.32.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 38.8MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (56.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=5b9ef1d7b768e742853f2c7abeab2472bd82a85324b5b1d6c9be9ffd7ca0b2ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, keras-applications, gast, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtRJhQMTwHl4",
        "outputId": "64f698dc-d535-42fb-901f-6aa2913609b5"
      },
      "source": [
        "!pip install bertviz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bertviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/5f/e4a5729cdf0ca6c8fbbbe2c7e15add55eab8868f2c6653ef92e4cfdaaa71/bertviz-1.1.0-py3-none-any.whl (153kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 12.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 30kB 21.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 51kB 25.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 61kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 71kB 28.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 81kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 92kB 30.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 102kB 29.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 112kB 29.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 122kB 29.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 133kB 29.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 143kB 29.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 29.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from bertviz) (2019.12.20)\n",
            "Collecting transformers>=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 32.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bertviz) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 31.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from bertviz) (1.17.69)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->bertviz) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->bertviz) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 30.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (3.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2.10)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.69 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz) (1.20.69)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz) (0.4.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz) (0.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.0->bertviz) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=2.0->bertviz) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.0->bertviz) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.0->bertviz) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.0->bertviz) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.69->boto3->bertviz) (2.8.1)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, bertviz\n",
            "Successfully installed bertviz-1.1.0 sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO7s80a8v-A8",
        "outputId": "03485082-11e0-4eae-aa24-b4fecc513c59"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkcdZQb-1sQE"
      },
      "source": [
        "import joblib\n",
        "tokenized_text = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/data/agritrend_tokenized.joblib\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P76JDa0jxTxJ"
      },
      "source": [
        "from bertviz import head_view\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1M1TqT1ByQe"
      },
      "source": [
        "# Load model and retrieve attention\n",
        "model_version = 'm-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0'\n",
        "do_lower_case = True\n",
        "model = BertModel.from_pretrained(model_version, output_attentions=True)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_version, do_lower_case=do_lower_case)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHoa3P3bynu9"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtUJe1bAxheY"
      },
      "source": [
        "filea = open('attentions.csv',\"w\")\n",
        "filet = open('tokens.csv',\"w\")\n",
        "for k in tokenized_text:\n",
        "  oring_to = np.array(k)\n",
        "  sentence_a =\"\"\n",
        "  i = 0\n",
        "  for kk in k:\n",
        "    if i == 0:\n",
        "      sentence_a = kk\n",
        "    else:\n",
        "      sentence_a = str(sentence_a) +\" \"+str(kk)\n",
        "    i = i+1\n",
        "  sentence_b = \"\"\n",
        "  inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
        "  token_type_ids = inputs['token_type_ids']\n",
        "  input_ids = inputs['input_ids']\n",
        "  attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
        "\n",
        "  attentions_values = []\n",
        "  for i in range(0,12):\n",
        "    heads_values = []\n",
        "    deatt = attention[i].detach().numpy()\n",
        "    for j in range(0,12):\n",
        "      matrix = np.array(deatt[0][j])\n",
        "      vett = matrix.sum(axis=0)\n",
        "      heads_values.append(vett)\n",
        "    heads_values = np.array(heads_values)\n",
        "    head = heads_values.sum(axis=0)\n",
        "    attentions_values.append(head)\n",
        "  attentions_values = np.array(attentions_values)\n",
        "  atts = attentions_values.sum(axis=0)\n",
        "  #print(atts)\n",
        "  tokens = oring_to\n",
        "  tag = False\n",
        "  tag_score = 0\n",
        "  tag_word = ''\n",
        "  ll = 0\n",
        "  new_att = []\n",
        "  new_tags=[]\n",
        "  coun = 0\n",
        "  for x in tokens:\n",
        "    if x != '[CLS]' and x !='[SEP]':\n",
        "      if tag:\n",
        "        if x == '>':\n",
        "          tag = False\n",
        "          coun = coun +1\n",
        "          tag_score = (tag_score + atts[ll])/ coun\n",
        "          tag_word = tag_word+x\n",
        "          new_tags.append(tag_word)\n",
        "          new_att.append(tag_score)\n",
        "          tag_score = 0\n",
        "          tag_word = ''\n",
        "          coun = 0\n",
        "        else:\n",
        "          if tag_word == '<' and x[0] not in ['u','h','n','e','p','t','d']:\n",
        "            tag = False\n",
        "            new_tags.append(tag_word)\n",
        "            new_att.append(tag_score)\n",
        "            tag_score = 0\n",
        "            tag_word = ''\n",
        "            coun = 0\n",
        "            new_tags.append(x)\n",
        "            new_att.append(atts[ll])\n",
        "            coun = coun +1\n",
        "          else:\n",
        "            coun = coun +1\n",
        "            tag_score += atts[ll]\n",
        "            tag_word += x.replace('##','')\n",
        "      else:\n",
        "        if x == '<':\n",
        "            tag = True\n",
        "            tag_score = tag_score + atts[ll]\n",
        "            tag_word = tag_word+x\n",
        "            coun = coun +1\n",
        "        else:\n",
        "            new_att.append(atts[ll])\n",
        "            new_tags.append(x)\n",
        "      ll = ll +1\n",
        "\n",
        "  #new_att = np.array(new_att)\n",
        "  new_att = np.array([ x /max(new_att) for x in new_att])\n",
        "  new_tags = np.array(new_tags)\n",
        "  #print(new_att)\n",
        "  #print(new_tags)\n",
        "  #print(np.array(oring_to).shape)\n",
        "  pp = 0\n",
        "  if len(new_att) == len(oring_to):\n",
        "    atts = ''\n",
        "    tos = ''\n",
        "    for pp in range (0,len(new_att)):\n",
        "      atts= atts+str(new_att[pp])+\",\"\n",
        "      tos = tos + str(new_tags[pp]+\",\")\n",
        "    atts = atts[:-1]+\"\\n\"\n",
        "    tos = tos[:-1]+\"\\n\"\n",
        "    filea.write(atts)\n",
        "    filea.flush()\n",
        "    filet.write(tos)\n",
        "    filet.flush()\n",
        "  else:\n",
        "    print(len(new_att))\n",
        "    print(oring_to)\n",
        "    print(new_tags)\n",
        "filea.close()\n",
        "filet.close()\n",
        "\n",
        "  #input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "  #tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}