{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABSITA_WMAL_Model2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-sf82movkvc",
        "outputId": "705b0625-b90d-45ed-a9cd-bf47916f1bf0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLlrzHzRv9XU"
      },
      "source": [
        "import joblib\n",
        "emb_matrix_train = joblib.load(\"/content/drive/MyDrive/absita_comfort_embedd_128_768_alberto_train.joblib\")\n",
        "wmal_matrix_train = joblib.load(\"/content/drive/MyDrive/wmal_train_comfort_128.joblib\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se9351L01RCX"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_DF = pd.read_csv(\"/content/drive/MyDrive/comfort_train_processed.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2deOEjg1W_e",
        "outputId": "f5b66615-7352-4059-f3fe-f226c5151a57"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# define example\n",
        "data = dataset_DF[\"pos\"]\n",
        "values = array(data)\n",
        "print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 ... 1 0 0]\n",
            "[0 1 1 ... 1 0 0]\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tc64TlXwys4",
        "outputId": "bd094474-09da-4bdf-c9ed-a0a825d80018"
      },
      "source": [
        "from keras.layers import Input, Dense, LSTM, Bidirectional, TimeDistributed, Flatten, Concatenate\n",
        "!pip install keras-self-attention"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.7/dist-packages (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOySvAIz3XeS"
      },
      "source": [
        "from keras_self_attention import SeqWeightedAttention, SeqSelfAttention"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaSsX9AewjPU"
      },
      "source": [
        "import keras\n",
        "input_emb = Input(shape=(128,768))\n",
        "input_wmal = Input(shape=(128,))\n",
        "\n",
        "#Bi-LSTM\n",
        "#bi = Bidirectional(LSTM(32, return_sequences=True))(input_emb)\n",
        "bi = LSTM(64, return_sequences=True)(input_emb)\n",
        "#att = SeqWeightedAttention()(bi)\n",
        "att = SeqSelfAttention(attention_width=15,attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
        "                       attention_activation=\"sigmoid\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(1e-6),\n",
        "                       bias_regularizer=keras.regularizers.l1(1e-4),\n",
        "                       attention_regularizer_weight=1e-4,\n",
        "                       use_attention_bias=True,return_attention=False) (bi)\n",
        "flat = Flatten()(att)\n",
        "\n",
        "#WMAL \n",
        "d1 = Dense(64) (input_wmal)\n",
        "\n",
        "#Concat\n",
        "concat = Concatenate(axis=1)([flat, d1])\n",
        "\n",
        "d2 = Dense(32) (concat)\n",
        "output = Dense(2,activation=\"softmax\") (d2)\n",
        "\n",
        "m = keras.Model(inputs=[input_emb,input_wmal], outputs=output)\n",
        "m.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzpaI6nT3pSw",
        "outputId": "5f4ab5f2-bd7b-437a-f41e-d0c5bd019bc2"
      },
      "source": [
        "m.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 768)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 128, 64)      213248      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " seq_self_attention (SeqSelfAtt  (None, 128, 64)     4097        ['lstm[0][0]']                   \n",
            " ention)                                                                                          \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 8192)         0           ['seq_self_attention[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           8256        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8256)         0           ['flatten[0][0]',                \n",
            "                                                                  'dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           264224      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 2)            66          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 489,891\n",
            "Trainable params: 489,891\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c__iZWCz32Tv",
        "outputId": "fffe4fa3-d2a4-40fd-b603-25cd9ad33903"
      },
      "source": [
        "m.fit([emb_matrix_train,wmal_matrix_train],onehot_encoded,batch_size=128, epochs=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 24s 985ms/step - loss: 0.3610 - accuracy: 0.8697\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 20s 972ms/step - loss: 0.1803 - accuracy: 0.9449\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 13s 583ms/step - loss: 0.1205 - accuracy: 0.9637\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 12s 567ms/step - loss: 0.0916 - accuracy: 0.9760\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 12s 567ms/step - loss: 0.0851 - accuracy: 0.9783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4afcecd290>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEm3BOiY8EHn"
      },
      "source": [
        "emb_matrix_test = joblib.load(\"/content/drive/MyDrive/absita_comfort_embedd_128_768_alberto_test.joblib\")\n",
        "dataset_test = pd.read_csv(\"/content/drive/MyDrive/comfort_test_processed.csv\")\n",
        "wmal_matrix_test = joblib.load(\"/content/drive/MyDrive/wmal_test_comfort_128.joblib\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ictcNZPP8TWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0b3535-95c0-49fe-b152-5161c22889c7"
      },
      "source": [
        "# define example\n",
        "data = dataset_test[\"pos\"]\n",
        "values = array(data)\n",
        "print(values)\n",
        "# integer encode\n",
        "integer_encoded_test = label_encoder.transform(values)\n",
        "##print(integer_encoded_test)\n",
        "# binary encode\n",
        "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
        "onehot_encoded_test = onehot_encoder.transform(integer_encoded_test)\n",
        "#print(onehot_encoded_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnGfTDKQ8tFG"
      },
      "source": [
        "predictions = m.predict([emb_matrix_test,wmal_matrix_test])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24u9a3jU87UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf42313-eccc-4591-c9fe-30e546eabcd4"
      },
      "source": [
        "print(predictions)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.9793649e-01 2.0635603e-03]\n",
            " [9.9793649e-01 2.0635603e-03]\n",
            " [9.8433244e-01 1.5667567e-02]\n",
            " ...\n",
            " [2.9571562e-03 9.9704283e-01]\n",
            " [8.9889736e-06 9.9999106e-01]\n",
            " [9.4732541e-01 5.2674618e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UG-0trQ9LMV"
      },
      "source": [
        "import numpy as np\n",
        "predictions_vec = np.zeros((1171,4))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC7taZDs9Y-_"
      },
      "source": [
        "i = 0\n",
        "confidences= []\n",
        "for item in predictions:\n",
        "  index = np.argmax(item);\n",
        "  confidences.append(item[index])\n",
        "  predictions_vec[i][index] = 1\n",
        "  i = i+1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs_Wp1cA9opa"
      },
      "source": [
        "labels_to_eval = []\n",
        "for vec in predictions_vec:\n",
        "  inverted = label_encoder.inverse_transform([argmax(vec)])[0]\n",
        "  labels_to_eval.append(inverted)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao9u_d0CEUC-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKk9jEKP9-rE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6aa2d78-18b7-46d4-8859-02784ba201f1"
      },
      "source": [
        "len(labels_to_eval)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1171"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD_9S_ANDrAo"
      },
      "source": [
        "dataset_test[\"predicted_label_neg\"] = labels_to_eval\n",
        "dataset_test[\"confidence_label_neg\"] = confidences"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxpF_Axq-F34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb50aa7-f972-43aa-8dfd-8b86ed5606e1"
      },
      "source": [
        "!pip install scikit-learn\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(dataset_test[\"pos\"],labels_to_eval,digits=5))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.92260   0.90030   0.91131       662\n",
            "           1    0.87429   0.90177   0.88781       509\n",
            "\n",
            "    accuracy                        0.90094      1171\n",
            "   macro avg    0.89844   0.90104   0.89956      1171\n",
            "weighted avg    0.90160   0.90094   0.90110      1171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFPdza90HcCF"
      },
      "source": [
        "dataset_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l346o4qL7HK"
      },
      "source": [
        "m.save(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/models/model_2_neg_absita.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Pkf6QWMTTw"
      },
      "source": [
        "#dataset_test.to_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/models/predictions_AGRITREND_neg_full_model2.csv\");"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}