{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENTIPOLC_WMAL_Model3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-sf82movkvc",
        "outputId": "45d075d0-bcf4-4847-f7d5-165b380e7b5f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLlrzHzRv9XU"
      },
      "source": [
        "import joblib\n",
        "emb_matrix_train = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/sentipol_embedd_7410_128_768_alberto_training.joblib\")\n",
        "wmal_matrix_train = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/sentipolc_wmal_training_7410_128.joblib\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se9351L01RCX"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_DF = pd.read_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/data/sentipolc_train_processed.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2deOEjg1W_e",
        "outputId": "aee3d5b1-4d89-424a-c498-0012d32decf7"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# define example\n",
        "data = dataset_DF[\"oneg\"]\n",
        "values = array(data)\n",
        "print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 1 0 0]\n",
            "[1 1 1 ... 1 0 0]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tc64TlXwys4",
        "outputId": "123974a4-8b82-4030-d3fe-0ae859b0b319"
      },
      "source": [
        "from keras.layers import Input, Dense, LSTM, Bidirectional, TimeDistributed, Flatten, Concatenate\n",
        "!pip install keras-self-attention"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.47.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.19.4)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-self-attention) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOySvAIz3XeS"
      },
      "source": [
        "from keras_self_attention import SeqWeightedAttention, SeqSelfAttention\n",
        "from keras.layers import Add, Multiply"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaSsX9AewjPU"
      },
      "source": [
        "import keras\n",
        "input_emb = Input(shape=(128,768))\n",
        "input_wmal = Input(shape=(128,))\n",
        "\n",
        "#Bi-LSTM\n",
        "#bi = Bidirectional(LSTM(32, return_sequences=True))(input_emb)\n",
        "bi = LSTM(64, return_sequences=True)(input_emb)\n",
        "#att = SeqWeightedAttention()(bi)\n",
        "att = SeqSelfAttention(attention_width=15,attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
        "                       attention_activation=\"sigmoid\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(1e-8),#(1e-6),\n",
        "                       bias_regularizer=keras.regularizers.l1(1e-8),#(1e-4),\n",
        "                       attention_regularizer_weight=1e-8,#1e-4,\n",
        "                       use_attention_bias=True,return_attention=False) (bi)\n",
        "\n",
        "app = Multiply() ([bi, att])                      \n",
        "flat = Flatten()(app)\n",
        "\n",
        "#WMAL \n",
        "d1 = Dense(64) (input_wmal)\n",
        "\n",
        "#Concat\n",
        "concat = Concatenate(axis=1)([flat, d1])\n",
        "\n",
        "d2 = Dense(32) (concat)\n",
        "output = Dense(2,activation=\"softmax\") (d2)\n",
        "\n",
        "m = keras.Model(inputs=[input_emb,input_wmal], outputs=output)\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.00005)\n",
        "m.compile(loss=\"categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzpaI6nT3pSw"
      },
      "source": [
        "m.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c__iZWCz32Tv",
        "outputId": "aa1706cb-b713-476b-c3ec-eae350adbff6"
      },
      "source": [
        "#13 epochs for pos - 0.00002\n",
        "#45 epochs for neg - 0.00005 - regularizers.l1(1e-4)\n",
        "m.fit([emb_matrix_train,wmal_matrix_train],onehot_encoded,batch_size=128, epochs=45,validation_split=0.15)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n",
            "50/50 [==============================] - 5s 54ms/step - loss: 0.6821 - accuracy: 0.5739 - val_loss: 0.6077 - val_accuracy: 0.7968\n",
            "Epoch 2/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6231 - accuracy: 0.6826 - val_loss: 0.4938 - val_accuracy: 0.8345\n",
            "Epoch 3/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5672 - accuracy: 0.7157 - val_loss: 0.4338 - val_accuracy: 0.8543\n",
            "Epoch 4/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5293 - accuracy: 0.7380 - val_loss: 0.4111 - val_accuracy: 0.8543\n",
            "Epoch 5/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.4974 - accuracy: 0.7551 - val_loss: 0.4041 - val_accuracy: 0.8462\n",
            "Epoch 6/45\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.4779 - accuracy: 0.7688 - val_loss: 0.4060 - val_accuracy: 0.8336\n",
            "Epoch 7/45\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4310 - val_accuracy: 0.8138\n",
            "Epoch 8/45\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.4317 - accuracy: 0.8012 - val_loss: 0.4024 - val_accuracy: 0.8228\n",
            "Epoch 9/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3984 - accuracy: 0.8208 - val_loss: 0.4187 - val_accuracy: 0.8112\n",
            "Epoch 10/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3805 - accuracy: 0.8325 - val_loss: 0.4031 - val_accuracy: 0.8219\n",
            "Epoch 11/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3660 - accuracy: 0.8371 - val_loss: 0.4217 - val_accuracy: 0.8112\n",
            "Epoch 12/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3373 - accuracy: 0.8620 - val_loss: 0.4259 - val_accuracy: 0.8103\n",
            "Epoch 13/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3205 - accuracy: 0.8670 - val_loss: 0.4299 - val_accuracy: 0.8103\n",
            "Epoch 14/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.2945 - accuracy: 0.8848 - val_loss: 0.4473 - val_accuracy: 0.8031\n",
            "Epoch 15/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.2817 - accuracy: 0.8893 - val_loss: 0.4396 - val_accuracy: 0.8156\n",
            "Epoch 16/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.2637 - accuracy: 0.9010 - val_loss: 0.4523 - val_accuracy: 0.8085\n",
            "Epoch 17/45\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.2324 - accuracy: 0.9238 - val_loss: 0.4829 - val_accuracy: 0.8013\n",
            "Epoch 18/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.2177 - accuracy: 0.9358 - val_loss: 0.4914 - val_accuracy: 0.7986\n",
            "Epoch 19/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1909 - accuracy: 0.9429 - val_loss: 0.5136 - val_accuracy: 0.7986\n",
            "Epoch 20/45\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.1746 - accuracy: 0.9498 - val_loss: 0.5309 - val_accuracy: 0.7995\n",
            "Epoch 21/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1480 - accuracy: 0.9659 - val_loss: 0.5539 - val_accuracy: 0.7914\n",
            "Epoch 22/45\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1390 - accuracy: 0.9719 - val_loss: 0.5313 - val_accuracy: 0.7995\n",
            "Epoch 23/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1300 - accuracy: 0.9706 - val_loss: 0.5685 - val_accuracy: 0.7941\n",
            "Epoch 24/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1120 - accuracy: 0.9760 - val_loss: 0.5743 - val_accuracy: 0.7950\n",
            "Epoch 25/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0993 - accuracy: 0.9781 - val_loss: 0.6130 - val_accuracy: 0.7950\n",
            "Epoch 26/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0936 - accuracy: 0.9809 - val_loss: 0.6429 - val_accuracy: 0.7932\n",
            "Epoch 27/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0763 - accuracy: 0.9862 - val_loss: 0.6003 - val_accuracy: 0.8004\n",
            "Epoch 28/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0702 - accuracy: 0.9891 - val_loss: 0.6361 - val_accuracy: 0.7995\n",
            "Epoch 29/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0619 - accuracy: 0.9903 - val_loss: 0.6720 - val_accuracy: 0.7923\n",
            "Epoch 30/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0535 - accuracy: 0.9919 - val_loss: 0.6888 - val_accuracy: 0.7932\n",
            "Epoch 31/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0498 - accuracy: 0.9945 - val_loss: 0.7099 - val_accuracy: 0.7941\n",
            "Epoch 32/45\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0442 - accuracy: 0.9956 - val_loss: 0.7008 - val_accuracy: 0.7968\n",
            "Epoch 33/45\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0394 - accuracy: 0.9945 - val_loss: 0.7252 - val_accuracy: 0.7977\n",
            "Epoch 34/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0329 - accuracy: 0.9966 - val_loss: 0.7785 - val_accuracy: 0.7905\n",
            "Epoch 35/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0308 - accuracy: 0.9975 - val_loss: 0.7536 - val_accuracy: 0.7950\n",
            "Epoch 36/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0295 - accuracy: 0.9964 - val_loss: 0.7874 - val_accuracy: 0.7941\n",
            "Epoch 37/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0253 - accuracy: 0.9976 - val_loss: 0.7887 - val_accuracy: 0.7950\n",
            "Epoch 38/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0218 - accuracy: 0.9974 - val_loss: 0.7799 - val_accuracy: 0.8022\n",
            "Epoch 39/45\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0205 - accuracy: 0.9983 - val_loss: 0.8530 - val_accuracy: 0.7878\n",
            "Epoch 40/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0189 - accuracy: 0.9985 - val_loss: 0.8503 - val_accuracy: 0.7887\n",
            "Epoch 41/45\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0158 - accuracy: 0.9984 - val_loss: 0.8414 - val_accuracy: 0.7959\n",
            "Epoch 42/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0157 - accuracy: 0.9987 - val_loss: 0.8339 - val_accuracy: 0.8022\n",
            "Epoch 43/45\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0141 - accuracy: 0.9988 - val_loss: 0.8589 - val_accuracy: 0.7959\n",
            "Epoch 44/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0130 - accuracy: 0.9985 - val_loss: 0.9075 - val_accuracy: 0.7923\n",
            "Epoch 45/45\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0125 - accuracy: 0.9985 - val_loss: 0.8989 - val_accuracy: 0.7950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4775fc1278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEm3BOiY8EHn"
      },
      "source": [
        "#emb_matrix_test = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/creagritrend_embedd_986_128_768_alberto.joblib\")\n",
        "#dataset_test = pd.read_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/data/creagritrend_processed.csv\")\n",
        "#wmal_matrix_test = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/creagritrend_wmal_agritrend_986_128.joblib\")\n",
        "\n",
        "emb_matrix_test = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/sentipol_embedd_2000_128_768_alberto_test.joblib\")\n",
        "dataset_test = pd.read_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/data/sentipolc_test_processed.csv\")\n",
        "wmal_matrix_test = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/sentipolc_wmal_test_2000_128.joblib\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ictcNZPP8TWc",
        "outputId": "d6261714-de6e-4ffe-cf46-7ac39833206a"
      },
      "source": [
        "# define example\n",
        "data = dataset_test[\"oneg\"]\n",
        "values = array(data)\n",
        "print(values)\n",
        "# integer encode\n",
        "integer_encoded_test = label_encoder.transform(values)\n",
        "##print(integer_encoded_test)\n",
        "# binary encode\n",
        "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
        "onehot_encoded_test = onehot_encoder.transform(integer_encoded_test)\n",
        "#print(onehot_encoded_test)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnGfTDKQ8tFG"
      },
      "source": [
        "predictions = m.predict([emb_matrix_test,wmal_matrix_test])"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24u9a3jU87UC",
        "outputId": "1edc40a9-4d12-4088-b36b-76fc26e1fdd1"
      },
      "source": [
        "print(predictions)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.7390586  0.26094136]\n",
            " [0.94952714 0.0504729 ]\n",
            " [0.64912707 0.35087293]\n",
            " ...\n",
            " [0.00960974 0.9903902 ]\n",
            " [0.0710268  0.92897326]\n",
            " [0.5566742  0.44332585]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UG-0trQ9LMV"
      },
      "source": [
        "import numpy as np\n",
        "predictions_vec = np.zeros((2000,4))\n",
        "\n",
        "i = 0\n",
        "confidences= []\n",
        "for item in predictions:\n",
        "  index = np.argmax(item);\n",
        "  confidences.append(item[index])\n",
        "  predictions_vec[i][index] = 1\n",
        "  i = i+1\n",
        "\n",
        "labels_to_eval = []\n",
        "for vec in predictions_vec:\n",
        "  inverted = label_encoder.inverse_transform([argmax(vec)])[0]\n",
        "  labels_to_eval.append(inverted)"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89dSnmWYsNaa",
        "outputId": "5e42b1a5-b548-45d1-83d5-e447b99889a8"
      },
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(dataset_test[\"oneg\"],labels_to_eval,digits=5))"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.76585   0.86423   0.81207      1230\n",
            "           1    0.72712   0.57792   0.64399       770\n",
            "\n",
            "    accuracy                        0.75400      2000\n",
            "   macro avg    0.74649   0.72107   0.72803      2000\n",
            "weighted avg    0.75094   0.75400   0.74736      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l346o4qL7HK"
      },
      "source": [
        "#m.save(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/models/model_3_neg_sentipolc_0.72803.h5\")"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Pkf6QWMTTw"
      },
      "source": [
        "#dataset_test.to_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/models/predictions_SENTIPOLC_neg_test_model3_0.72803.csv\");"
      ],
      "execution_count": 218,
      "outputs": []
    }
  ]
}