{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AGRITREND_WMAL_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-sf82movkvc",
        "outputId": "d8b75431-7c90-4cd2-8ad3-7a93a65f030e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLlrzHzRv9XU"
      },
      "source": [
        "import joblib\n",
        "emb_matrix_train = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/sentipol_embedd_7410_128_768_alberto_training.joblib\")\n",
        "wmal_matrix_train = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/sentipolc_wmal_training_7410_128.joblib\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se9351L01RCX"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_DF = pd.read_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/data/sentipolc_train_processed.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2deOEjg1W_e",
        "outputId": "df60360e-84c7-42fd-9fd0-372b8e92e866"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# define example\n",
        "data = dataset_DF[\"oneg\"]\n",
        "values = array(data)\n",
        "print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 1 0 0]\n",
            "[1 1 1 ... 1 0 0]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tc64TlXwys4",
        "outputId": "7de4851a-28a8-4687-a660-2caaa4bbac42"
      },
      "source": [
        "from keras.layers import Input, Dense, LSTM, Bidirectional, TimeDistributed, Flatten, Concatenate\n",
        "!pip install keras-self-attention"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.47.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-self-attention) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOySvAIz3XeS"
      },
      "source": [
        "from keras_self_attention import SeqWeightedAttention"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaSsX9AewjPU"
      },
      "source": [
        "import keras\n",
        "input_emb = Input(shape=(128,768))\n",
        "input_wmal = Input(shape=(128,))\n",
        "\n",
        "#Bi-LSTM\n",
        "bi = Bidirectional(LSTM(32, return_sequences=True))(input_emb)\n",
        "att = SeqWeightedAttention()(bi)\n",
        "flat = Flatten()(att)\n",
        "\n",
        "#WMAL \n",
        "d1 = Dense(64) (input_wmal)\n",
        "\n",
        "#Concat\n",
        "concat = Concatenate(axis=1)([flat, d1])\n",
        "\n",
        "d2 = Dense(32) (concat)\n",
        "output = Dense(2,activation=\"softmax\") (d2)\n",
        "\n",
        "m = keras.Model(inputs=[input_emb,input_wmal], outputs=output)\n",
        "m.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzpaI6nT3pSw",
        "outputId": "79f524f6-a9cb-463f-a03b-23a167a324fc"
      },
      "source": [
        "m.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 768)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 128, 64)      205056      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "seq_weighted_attention (SeqWeig (None, 64)           65          bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           seq_weighted_attention[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 64)           8256        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 128)          0           flatten[0][0]                    \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           4128        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            66          dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 217,571\n",
            "Trainable params: 217,571\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c__iZWCz32Tv",
        "outputId": "9f70220d-c1b1-45dc-bee9-073e1d6d5e11"
      },
      "source": [
        "m.fit([emb_matrix_train,wmal_matrix_train],onehot_encoded,batch_size=128, epochs=8)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "58/58 [==============================] - 29s 495ms/step - loss: 0.5499 - accuracy: 0.7112\n",
            "Epoch 2/8\n",
            "58/58 [==============================] - 29s 493ms/step - loss: 0.4493 - accuracy: 0.7854\n",
            "Epoch 3/8\n",
            "58/58 [==============================] - 28s 484ms/step - loss: 0.3924 - accuracy: 0.8165\n",
            "Epoch 4/8\n",
            "58/58 [==============================] - 28s 488ms/step - loss: 0.3204 - accuracy: 0.8592\n",
            "Epoch 5/8\n",
            "58/58 [==============================] - 28s 486ms/step - loss: 0.2223 - accuracy: 0.9082\n",
            "Epoch 6/8\n",
            "58/58 [==============================] - 28s 481ms/step - loss: 0.1334 - accuracy: 0.9499\n",
            "Epoch 7/8\n",
            "58/58 [==============================] - 28s 482ms/step - loss: 0.0721 - accuracy: 0.9760\n",
            "Epoch 8/8\n",
            "58/58 [==============================] - 28s 490ms/step - loss: 0.0382 - accuracy: 0.9874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbe60bd7b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEm3BOiY8EHn"
      },
      "source": [
        "emb_matrix_test = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/creagritrend_embedd_986_128_768_alberto.joblib\")\n",
        "dataset_test = pd.read_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/data/creagritrend_processed.csv\")\n",
        "wmal_matrix_test = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/creagritrend_wmal_agritrend_986_128.joblib\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ictcNZPP8TWc",
        "outputId": "c4007431-a719-48cf-88f5-8461c27e38b6"
      },
      "source": [
        "# define example\n",
        "data = dataset_test[\"label_neg\"]\n",
        "values = array(data)\n",
        "print(values)\n",
        "# integer encode\n",
        "integer_encoded_test = label_encoder.transform(values)\n",
        "print(integer_encoded_test)\n",
        "# binary encode\n",
        "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
        "onehot_encoded_test = onehot_encoder.transform(integer_encoded_test)\n",
        "print(onehot_encoded_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0\n",
            " 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0\n",
            " 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0\n",
            " 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1\n",
            " 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0\n",
            " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
            " 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0\n",
            " 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0\n",
            " 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0\n",
            " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0\n",
            " 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1\n",
            " 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0]\n",
            "[0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0\n",
            " 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0\n",
            " 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0\n",
            " 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1\n",
            " 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0\n",
            " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
            " 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0\n",
            " 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0\n",
            " 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0\n",
            " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0\n",
            " 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1\n",
            " 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0]\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnGfTDKQ8tFG"
      },
      "source": [
        "predictions = m.predict([emb_matrix_test,wmal_matrix_test])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24u9a3jU87UC",
        "outputId": "71a34c9f-6824-4d8d-f2e3-80b433f8e87f"
      },
      "source": [
        "print(predictions)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0000000e+00 2.2970085e-08]\n",
            " [9.9982798e-01 1.7202580e-04]\n",
            " [9.9995875e-01 4.1254432e-05]\n",
            " ...\n",
            " [9.9762517e-01 2.3747978e-03]\n",
            " [9.9999917e-01 8.2827910e-07]\n",
            " [1.0000000e+00 8.8940801e-09]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UG-0trQ9LMV"
      },
      "source": [
        "import numpy as np\n",
        "predictions_vec = np.zeros((986,4))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC7taZDs9Y-_"
      },
      "source": [
        "i = 0\n",
        "confidences= []\n",
        "for item in predictions:\n",
        "  index = np.argmax(item);\n",
        "  confidences.append(item[index])\n",
        "  predictions_vec[i][index] = 1\n",
        "  i = i+1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs_Wp1cA9opa"
      },
      "source": [
        "labels_to_eval = []\n",
        "for vec in predictions_vec:\n",
        "  inverted = label_encoder.inverse_transform([argmax(vec)])[0]\n",
        "  labels_to_eval.append(inverted)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao9u_d0CEUC-",
        "outputId": "fccfe240-7afc-4dc9-b09b-02afb02058c4"
      },
      "source": [
        "confidences"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 0.999828,\n",
              " 0.99995875,\n",
              " 0.9999821,\n",
              " 0.73015577,\n",
              " 0.9983681,\n",
              " 1.0,\n",
              " 0.9999995,\n",
              " 1.0,\n",
              " 0.9999999,\n",
              " 0.99990594,\n",
              " 1.0,\n",
              " 0.9999598,\n",
              " 0.9467617,\n",
              " 0.9999504,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.999995,\n",
              " 1.0,\n",
              " 0.99999666,\n",
              " 1.0,\n",
              " 0.9611984,\n",
              " 1.0,\n",
              " 0.9999486,\n",
              " 0.9980725,\n",
              " 0.9999999,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.9999975,\n",
              " 0.9934449,\n",
              " 0.99999976,\n",
              " 0.99999976,\n",
              " 0.5700783,\n",
              " 0.99999845,\n",
              " 0.9714239,\n",
              " 0.99999714,\n",
              " 0.9999045,\n",
              " 0.9963642,\n",
              " 0.85809815,\n",
              " 0.99998593,\n",
              " 0.9314763,\n",
              " 0.9987197,\n",
              " 0.99999416,\n",
              " 0.99999964,\n",
              " 0.98327523,\n",
              " 0.99999774,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6775981,\n",
              " 0.99999917,\n",
              " 0.9999999,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.9999013,\n",
              " 0.9999957,\n",
              " 0.99999785,\n",
              " 1.0,\n",
              " 0.999985,\n",
              " 0.99996483,\n",
              " 0.99999917,\n",
              " 1.0,\n",
              " 0.9997334,\n",
              " 0.9999542,\n",
              " 0.9999908,\n",
              " 0.9999174,\n",
              " 0.9999988,\n",
              " 0.99999917,\n",
              " 0.99999976,\n",
              " 1.0,\n",
              " 0.99894685,\n",
              " 0.99998724,\n",
              " 0.9999367,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.78245604,\n",
              " 0.996406,\n",
              " 1.0,\n",
              " 0.97918016,\n",
              " 0.999985,\n",
              " 0.9999949,\n",
              " 1.0,\n",
              " 0.999984,\n",
              " 0.9799855,\n",
              " 1.0,\n",
              " 0.99821544,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9999943,\n",
              " 0.99999523,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9997743,\n",
              " 0.9999895,\n",
              " 0.9993106,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.98587453,\n",
              " 0.9959259,\n",
              " 0.9999995,\n",
              " 1.0,\n",
              " 0.9999993,\n",
              " 0.99994767,\n",
              " 0.9684553,\n",
              " 1.0,\n",
              " 0.9999993,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.9999962,\n",
              " 0.9999962,\n",
              " 0.9999379,\n",
              " 0.99999404,\n",
              " 0.97505593,\n",
              " 1.0,\n",
              " 0.99800354,\n",
              " 1.0,\n",
              " 0.9999926,\n",
              " 0.99999917,\n",
              " 0.99999964,\n",
              " 0.99999917,\n",
              " 0.9997539,\n",
              " 0.9999987,\n",
              " 0.99999857,\n",
              " 1.0,\n",
              " 0.99999964,\n",
              " 0.9999801,\n",
              " 0.99999845,\n",
              " 0.9999995,\n",
              " 0.99828666,\n",
              " 0.9993542,\n",
              " 0.98398304,\n",
              " 0.9999958,\n",
              " 0.98881197,\n",
              " 1.0,\n",
              " 0.9997712,\n",
              " 0.88153565,\n",
              " 0.69216716,\n",
              " 0.99999964,\n",
              " 0.9999999,\n",
              " 0.9644876,\n",
              " 0.93498075,\n",
              " 0.99992394,\n",
              " 1.0,\n",
              " 0.99990594,\n",
              " 0.9995178,\n",
              " 1.0,\n",
              " 0.9999722,\n",
              " 0.9999833,\n",
              " 0.99999917,\n",
              " 0.99999976,\n",
              " 0.9999527,\n",
              " 0.8546949,\n",
              " 0.9678843,\n",
              " 0.99999917,\n",
              " 0.99998236,\n",
              " 0.9999982,\n",
              " 1.0,\n",
              " 0.9889604,\n",
              " 0.9576685,\n",
              " 0.98151416,\n",
              " 0.9999949,\n",
              " 1.0,\n",
              " 0.9999962,\n",
              " 1.0,\n",
              " 0.98543406,\n",
              " 1.0,\n",
              " 0.9997348,\n",
              " 0.99996173,\n",
              " 0.9999912,\n",
              " 0.99999917,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.82467943,\n",
              " 0.990252,\n",
              " 0.9973137,\n",
              " 0.9999137,\n",
              " 0.99994373,\n",
              " 0.9999989,\n",
              " 0.996223,\n",
              " 0.99228,\n",
              " 0.9999995,\n",
              " 1.0,\n",
              " 0.9939126,\n",
              " 0.9999976,\n",
              " 0.9999989,\n",
              " 0.9999994,\n",
              " 0.99866045,\n",
              " 1.0,\n",
              " 0.5296869,\n",
              " 0.9999747,\n",
              " 0.99389887,\n",
              " 1.0,\n",
              " 0.99971384,\n",
              " 1.0,\n",
              " 0.9999995,\n",
              " 0.9999976,\n",
              " 0.9810037,\n",
              " 0.9999107,\n",
              " 0.99999833,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99999976,\n",
              " 0.999992,\n",
              " 0.99999976,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9998379,\n",
              " 0.99999917,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99998057,\n",
              " 0.9999932,\n",
              " 0.99999785,\n",
              " 0.94973814,\n",
              " 0.9998466,\n",
              " 0.9999982,\n",
              " 1.0,\n",
              " 0.7878785,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9999902,\n",
              " 0.999956,\n",
              " 1.0,\n",
              " 0.9960665,\n",
              " 0.9999988,\n",
              " 0.96001244,\n",
              " 1.0,\n",
              " 0.9998429,\n",
              " 0.9973248,\n",
              " 0.9953178,\n",
              " 0.9899414,\n",
              " 0.87825537,\n",
              " 0.99976295,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.9999999,\n",
              " 0.99995923,\n",
              " 1.0,\n",
              " 0.5318705,\n",
              " 0.99999917,\n",
              " 0.9997327,\n",
              " 1.0,\n",
              " 0.99843603,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.99999964,\n",
              " 0.99135756,\n",
              " 0.9945931,\n",
              " 0.9054392,\n",
              " 0.99999154,\n",
              " 0.999998,\n",
              " 1.0,\n",
              " 0.98820704,\n",
              " 0.9999988,\n",
              " 0.999997,\n",
              " 0.83424366,\n",
              " 0.81023073,\n",
              " 0.9999976,\n",
              " 0.99999917,\n",
              " 0.9994148,\n",
              " 0.99998856,\n",
              " 0.99977034,\n",
              " 0.9997235,\n",
              " 0.9999924,\n",
              " 0.99999976,\n",
              " 0.99999917,\n",
              " 1.0,\n",
              " 0.99942434,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99999976,\n",
              " 0.99998164,\n",
              " 0.9994388,\n",
              " 0.99973446,\n",
              " 1.0,\n",
              " 0.98731136,\n",
              " 0.9306774,\n",
              " 0.99999976,\n",
              " 0.9999975,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.9999945,\n",
              " 0.96808016,\n",
              " 0.999966,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.999982,\n",
              " 0.99425644,\n",
              " 0.74188876,\n",
              " 0.9999522,\n",
              " 1.0,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.9999937,\n",
              " 0.9969284,\n",
              " 0.9999962,\n",
              " 1.0,\n",
              " 0.9999988,\n",
              " 0.9999994,\n",
              " 0.9999757,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9999999,\n",
              " 0.99999857,\n",
              " 0.9999788,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9999988,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9874955,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99999607,\n",
              " 0.99974805,\n",
              " 1.0,\n",
              " 0.9992754,\n",
              " 0.99991727,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.6573045,\n",
              " 0.9999298,\n",
              " 1.0,\n",
              " 0.99999976,\n",
              " 0.9999906,\n",
              " 0.8660687,\n",
              " 0.9999993,\n",
              " 0.99996436,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9998704,\n",
              " 0.9988385,\n",
              " 0.99999785,\n",
              " 1.0,\n",
              " 0.97446436,\n",
              " 1.0,\n",
              " 0.9961366,\n",
              " 0.99999905,\n",
              " 0.99999964,\n",
              " 0.99999964,\n",
              " 0.99971515,\n",
              " 0.6302028,\n",
              " 0.9962668,\n",
              " 1.0,\n",
              " 0.9989073,\n",
              " 0.9999926,\n",
              " 1.0,\n",
              " 0.9950537,\n",
              " 0.9999968,\n",
              " 0.7697406,\n",
              " 1.0,\n",
              " 0.99999905,\n",
              " 0.9999999,\n",
              " 0.9999827,\n",
              " 0.99906355,\n",
              " 0.9966762,\n",
              " 1.0,\n",
              " 0.9999999,\n",
              " 0.9994252,\n",
              " 0.59094954,\n",
              " 1.0,\n",
              " 0.9999989,\n",
              " 0.9999944,\n",
              " 0.9999969,\n",
              " 0.9791166,\n",
              " 0.9956552,\n",
              " 0.9999944,\n",
              " 0.99866426,\n",
              " 0.9999995,\n",
              " 0.99999917,\n",
              " 0.9999994,\n",
              " 0.99994254,\n",
              " 0.9994324,\n",
              " 0.99974734,\n",
              " 0.9999871,\n",
              " 0.9997348,\n",
              " 0.9999902,\n",
              " 0.9999958,\n",
              " 0.99999917,\n",
              " 0.9999989,\n",
              " 0.9983321,\n",
              " 0.99878055,\n",
              " 1.0,\n",
              " 0.9996246,\n",
              " 0.9997961,\n",
              " 0.9717419,\n",
              " 0.9999969,\n",
              " 0.99999976,\n",
              " 0.99999523,\n",
              " 0.9999771,\n",
              " 0.99999917,\n",
              " 0.99997234,\n",
              " 0.6133316,\n",
              " 1.0,\n",
              " 0.99997914,\n",
              " 0.9997223,\n",
              " 0.99999166,\n",
              " 1.0,\n",
              " 0.99996793,\n",
              " 1.0,\n",
              " 0.99998593,\n",
              " 0.99999464,\n",
              " 0.9963104,\n",
              " 1.0,\n",
              " 0.9999951,\n",
              " 1.0,\n",
              " 0.99513644,\n",
              " 0.9999994,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99257374,\n",
              " 0.9999951,\n",
              " 1.0,\n",
              " 0.997724,\n",
              " 0.999869,\n",
              " 0.9999949,\n",
              " 0.9999958,\n",
              " 0.99999917,\n",
              " 0.99999917,\n",
              " 0.9999995,\n",
              " 0.99999964,\n",
              " 0.98379046,\n",
              " 0.99996483,\n",
              " 1.0,\n",
              " 0.99996555,\n",
              " 0.6606692,\n",
              " 0.99999917,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99929607,\n",
              " 0.9999964,\n",
              " 0.9999902,\n",
              " 0.9999962,\n",
              " 0.80296016,\n",
              " 0.9975871,\n",
              " 1.0,\n",
              " 0.9999542,\n",
              " 0.99808645,\n",
              " 0.9998802,\n",
              " 1.0,\n",
              " 0.8331182,\n",
              " 1.0,\n",
              " 0.9999864,\n",
              " 0.9345468,\n",
              " 1.0,\n",
              " 0.9999902,\n",
              " 0.9999999,\n",
              " 0.9999875,\n",
              " 0.98826104,\n",
              " 0.8231086,\n",
              " 0.9989594,\n",
              " 1.0,\n",
              " 0.9999987,\n",
              " 0.79595894,\n",
              " 1.0,\n",
              " 0.9999999,\n",
              " 0.99999845,\n",
              " 0.99999976,\n",
              " 1.0,\n",
              " 0.99999833,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.999995,\n",
              " 1.0,\n",
              " 0.7735126,\n",
              " 0.9879951,\n",
              " 1.0,\n",
              " 0.99999833,\n",
              " 1.0,\n",
              " 0.9999385,\n",
              " 0.9999914,\n",
              " 0.99680376,\n",
              " 0.9998665,\n",
              " 1.0,\n",
              " 0.9995652,\n",
              " 0.99999344,\n",
              " 1.0,\n",
              " 0.99998605,\n",
              " 0.999997,\n",
              " 0.9998882,\n",
              " 0.99941003,\n",
              " 1.0,\n",
              " 0.9876824,\n",
              " 0.5032976,\n",
              " 1.0,\n",
              " 0.9986406,\n",
              " 0.9999951,\n",
              " 0.9136312,\n",
              " 0.9928646,\n",
              " 0.9993818,\n",
              " 0.9802822,\n",
              " 0.9994795,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99999154,\n",
              " 0.999863,\n",
              " 1.0,\n",
              " 0.99989986,\n",
              " 1.0,\n",
              " 0.99999857,\n",
              " 0.62632155,\n",
              " 0.98544693,\n",
              " 0.9999354,\n",
              " 0.9999695,\n",
              " 0.8121532,\n",
              " 0.99984264,\n",
              " 0.99999166,\n",
              " 1.0,\n",
              " 0.9999994,\n",
              " 0.99999714,\n",
              " 0.99927634,\n",
              " 0.9999852,\n",
              " 0.9999999,\n",
              " 0.9997278,\n",
              " 0.9207968,\n",
              " 0.9999999,\n",
              " 0.99961853,\n",
              " 0.9927019,\n",
              " 0.9999995,\n",
              " 0.9999994,\n",
              " 0.99998736,\n",
              " 0.99995255,\n",
              " 1.0,\n",
              " 0.62116927,\n",
              " 0.91692865,\n",
              " 0.9765514,\n",
              " 0.9998091,\n",
              " 0.9999273,\n",
              " 0.99995816,\n",
              " 0.8691329,\n",
              " 1.0,\n",
              " 0.999992,\n",
              " 0.9999995,\n",
              " 0.99999225,\n",
              " 0.99999917,\n",
              " 0.7831998,\n",
              " 0.9973205,\n",
              " 0.9854011,\n",
              " 0.99999523,\n",
              " 0.5756082,\n",
              " 0.9999372,\n",
              " 0.99998116,\n",
              " 0.80021065,\n",
              " 0.9999999,\n",
              " 0.99999845,\n",
              " 0.99196213,\n",
              " 0.89392394,\n",
              " 0.8306172,\n",
              " 0.9999633,\n",
              " 0.99968636,\n",
              " 0.999998,\n",
              " 0.9975758,\n",
              " 0.9650566,\n",
              " 0.99718755,\n",
              " 0.6399157,\n",
              " 0.99999297,\n",
              " 0.99991477,\n",
              " 0.98137754,\n",
              " 0.7890891,\n",
              " 0.9991304,\n",
              " 1.0,\n",
              " 0.99997807,\n",
              " 0.9944252,\n",
              " 0.9998634,\n",
              " 0.66892654,\n",
              " 0.999998,\n",
              " 1.0,\n",
              " 0.9999994,\n",
              " 0.9999994,\n",
              " 1.0,\n",
              " 0.99998975,\n",
              " 0.9311547,\n",
              " 0.9942011,\n",
              " 0.99995065,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99965537,\n",
              " 0.9999945,\n",
              " 1.0,\n",
              " 0.9991074,\n",
              " 0.9847168,\n",
              " 0.62557036,\n",
              " 0.99985015,\n",
              " 0.9998745,\n",
              " 0.9999907,\n",
              " 0.9998758,\n",
              " 1.0,\n",
              " 0.99333924,\n",
              " 0.92476386,\n",
              " 0.9999962,\n",
              " 1.0,\n",
              " 0.9999999,\n",
              " 0.60117066,\n",
              " 0.9754705,\n",
              " 0.99970895,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.988708,\n",
              " 0.9869228,\n",
              " 1.0,\n",
              " 0.9999975,\n",
              " 0.9919823,\n",
              " 0.99999845,\n",
              " 0.99363565,\n",
              " 0.99999857,\n",
              " 0.99994385,\n",
              " 0.79750466,\n",
              " 1.0,\n",
              " 0.9998055,\n",
              " 0.9984762,\n",
              " 0.9755373,\n",
              " 0.9999825,\n",
              " 0.8071553,\n",
              " 0.9997962,\n",
              " 0.99993896,\n",
              " 0.99999905,\n",
              " 0.60090506,\n",
              " 0.9959812,\n",
              " 1.0,\n",
              " 0.9997291,\n",
              " 1.0,\n",
              " 0.9999994,\n",
              " 0.9999999,\n",
              " 0.9995377,\n",
              " 0.9999999,\n",
              " 0.9999423,\n",
              " 1.0,\n",
              " 0.62296283,\n",
              " 0.9997459,\n",
              " 0.9978041,\n",
              " 0.9999999,\n",
              " 0.9999999,\n",
              " 0.9989862,\n",
              " 0.95423657,\n",
              " 0.99999905,\n",
              " 0.9999993,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8355898,\n",
              " 0.999979,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99980325,\n",
              " 0.9999993,\n",
              " 1.0,\n",
              " 0.9999995,\n",
              " 0.99999845,\n",
              " 0.9999999,\n",
              " 0.9999999,\n",
              " 0.6709396,\n",
              " 0.7168862,\n",
              " 0.99945885,\n",
              " 0.98410565,\n",
              " 0.99999833,\n",
              " 0.9999999,\n",
              " 0.9999995,\n",
              " 0.99588025,\n",
              " 0.99997663,\n",
              " 0.83808416,\n",
              " 0.99999976,\n",
              " 1.0,\n",
              " 0.9999001,\n",
              " 0.99999595,\n",
              " 0.9999999,\n",
              " 0.9995826,\n",
              " 0.9999987,\n",
              " 1.0,\n",
              " 0.7225815,\n",
              " 0.9999999,\n",
              " 0.9697296,\n",
              " 0.99844956,\n",
              " 1.0,\n",
              " 0.54500747,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9999976,\n",
              " 1.0,\n",
              " 0.84071803,\n",
              " 0.9999999,\n",
              " 0.9999908,\n",
              " 0.99999547,\n",
              " 0.8197131,\n",
              " 0.99999976,\n",
              " 0.66882265,\n",
              " 0.9999999,\n",
              " 0.9999943,\n",
              " 0.9999832,\n",
              " 0.9999994,\n",
              " 1.0,\n",
              " 0.91336656,\n",
              " 0.98876977,\n",
              " 0.9999999,\n",
              " 0.99603707,\n",
              " 0.99993956,\n",
              " 0.99999416,\n",
              " 1.0,\n",
              " 0.9995679,\n",
              " 0.9999819,\n",
              " 0.9999999,\n",
              " 0.9999931,\n",
              " 1.0,\n",
              " 0.9999887,\n",
              " 0.5077018,\n",
              " 0.8981262,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9938309,\n",
              " 0.990699,\n",
              " 0.9999993,\n",
              " 0.99995434,\n",
              " 1.0,\n",
              " 0.99999917,\n",
              " 0.99999774,\n",
              " 1.0,\n",
              " 0.9885428,\n",
              " 0.99851257,\n",
              " 1.0,\n",
              " 0.9994766,\n",
              " 0.9999777,\n",
              " 0.9840985,\n",
              " 0.99998677,\n",
              " 0.99999225,\n",
              " 0.971099,\n",
              " 0.9997832,\n",
              " 0.9998938,\n",
              " 0.9999051,\n",
              " 0.99998856,\n",
              " 0.9999999,\n",
              " 0.9999199,\n",
              " 1.0,\n",
              " 0.99865615,\n",
              " 0.99999976,\n",
              " 0.9999933,\n",
              " 0.9999987,\n",
              " 0.99425876,\n",
              " 0.9999999,\n",
              " 0.9966876,\n",
              " 0.9999993,\n",
              " 1.0,\n",
              " 0.9990069,\n",
              " 0.99999976,\n",
              " 0.99993646,\n",
              " 0.9996599,\n",
              " 0.99999976,\n",
              " 0.9999982,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99999535,\n",
              " 0.9999999,\n",
              " 0.5050807,\n",
              " 0.9998871,\n",
              " 0.9996952,\n",
              " 0.9999988,\n",
              " 0.99986434,\n",
              " 1.0,\n",
              " 0.979324,\n",
              " 0.9835961,\n",
              " 0.9650747,\n",
              " 0.999998,\n",
              " 0.8708397,\n",
              " 0.99975795,\n",
              " 0.9992275,\n",
              " 0.92689896,\n",
              " 0.8956481,\n",
              " 1.0,\n",
              " 0.9992465,\n",
              " 1.0,\n",
              " 0.9998136,\n",
              " 0.99813336,\n",
              " 0.9999429,\n",
              " 0.9999851,\n",
              " 1.0,\n",
              " 0.9999976,\n",
              " 0.99999845,\n",
              " 0.9993285,\n",
              " 0.9993637,\n",
              " 0.96057785,\n",
              " 0.9861076,\n",
              " 0.9837445,\n",
              " 0.99997854,\n",
              " 0.99977344,\n",
              " 0.99992883,\n",
              " 0.9990877,\n",
              " 0.97067034,\n",
              " 1.0,\n",
              " 0.9999956,\n",
              " 0.9999938,\n",
              " 1.0,\n",
              " 0.7881941,\n",
              " 1.0,\n",
              " 0.9999962,\n",
              " 0.9999701,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.985159,\n",
              " 0.9722944,\n",
              " 0.64730537,\n",
              " 1.0,\n",
              " 0.8605665,\n",
              " 0.8722112,\n",
              " 0.99999774,\n",
              " 0.99999976,\n",
              " 0.9996125,\n",
              " 0.99981505,\n",
              " 0.99999964,\n",
              " 0.99999356,\n",
              " 0.92133695,\n",
              " 0.9695198,\n",
              " 0.6817101,\n",
              " 1.0,\n",
              " 0.9999927,\n",
              " 0.9789985,\n",
              " 0.5839148,\n",
              " 1.0,\n",
              " 0.9940049,\n",
              " 0.9999881,\n",
              " 0.99995506,\n",
              " 0.9996846,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.97679716,\n",
              " 0.99999976,\n",
              " 0.7486755,\n",
              " 0.999961,\n",
              " 0.9999926,\n",
              " 0.9998938,\n",
              " 0.988976,\n",
              " 0.99999976,\n",
              " 0.9999982,\n",
              " 0.99974793,\n",
              " 0.99999785,\n",
              " 1.0,\n",
              " 0.99999976,\n",
              " 0.9999969,\n",
              " 1.0,\n",
              " 0.9999995,\n",
              " 0.9999989,\n",
              " 0.9999999,\n",
              " 0.9999957,\n",
              " 0.99999654,\n",
              " 0.9999993,\n",
              " 0.993156,\n",
              " 0.99572986,\n",
              " 0.99964035,\n",
              " 1.0,\n",
              " 0.9678064,\n",
              " 1.0,\n",
              " 0.69429195,\n",
              " 0.99999714,\n",
              " 0.9998882,\n",
              " 1.0,\n",
              " 0.99922264,\n",
              " 0.9999994,\n",
              " 0.99999,\n",
              " 0.9999782,\n",
              " 0.9999964,\n",
              " 0.73328185,\n",
              " 0.99996006,\n",
              " 0.99999297,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99999034,\n",
              " 0.9999944,\n",
              " 0.9982096,\n",
              " 0.99898,\n",
              " 0.9999995,\n",
              " 0.9999002,\n",
              " 0.9848744,\n",
              " 0.726423,\n",
              " 1.0,\n",
              " 0.9438883,\n",
              " 1.0,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9992397,\n",
              " 0.99999917,\n",
              " 0.9999976,\n",
              " 0.99999964,\n",
              " 0.9963325,\n",
              " 0.9999999,\n",
              " 0.99923515,\n",
              " 0.9999993,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9999994,\n",
              " 0.99999416,\n",
              " 0.9999988,\n",
              " 0.9999958,\n",
              " 0.91862017,\n",
              " 0.9999914,\n",
              " 1.0,\n",
              " 0.99998975,\n",
              " 0.9999999,\n",
              " 0.99998057,\n",
              " 0.9999074,\n",
              " 0.86519516,\n",
              " 0.9794007,\n",
              " 0.9157016,\n",
              " 0.99999833,\n",
              " 0.9999999,\n",
              " 0.73714477,\n",
              " 1.0,\n",
              " 0.9999994,\n",
              " 0.99999607,\n",
              " 0.99244225,\n",
              " 0.9880432,\n",
              " 0.9991928,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.99993634,\n",
              " 1.0,\n",
              " 0.9845536,\n",
              " 0.6814408,\n",
              " 0.9999968,\n",
              " 0.9985746,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.98526776,\n",
              " 0.99999666,\n",
              " 1.0,\n",
              " 0.6733782,\n",
              " 0.9999254,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.9968363,\n",
              " 1.0,\n",
              " 0.99998045,\n",
              " 0.99999964,\n",
              " 0.91967875,\n",
              " 0.9999707,\n",
              " 1.0,\n",
              " 0.9998288,\n",
              " 0.99993503,\n",
              " 0.9996779,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9971974,\n",
              " 0.99903405,\n",
              " 0.99999714,\n",
              " 0.99988186,\n",
              " 0.99978906,\n",
              " 0.9998697,\n",
              " 0.9999428,\n",
              " 0.9995635,\n",
              " 0.9543864,\n",
              " 0.99999964,\n",
              " 0.9999999,\n",
              " 0.99999964,\n",
              " 1.0,\n",
              " 0.6552229,\n",
              " 0.99230945,\n",
              " 0.99999344,\n",
              " 0.999681,\n",
              " 0.99992836,\n",
              " 1.0,\n",
              " 0.99965775,\n",
              " 1.0,\n",
              " 0.99999964,\n",
              " 0.9999999,\n",
              " 1.0,\n",
              " 0.99999535,\n",
              " 0.999997,\n",
              " 0.99896145,\n",
              " 0.9999993,\n",
              " 0.9807552,\n",
              " 0.99996257,\n",
              " 0.9999988,\n",
              " 0.9976252,\n",
              " 0.99999917,\n",
              " 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKk9jEKP9-rE",
        "outputId": "1f59e083-0e6b-4716-e683-30318ee9f90b"
      },
      "source": [
        "len(labels_to_eval)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD_9S_ANDrAo"
      },
      "source": [
        "dataset_test[\"predicted_label_neg\"] = labels_to_eval\n",
        "dataset_test[\"confidence_label_neg\"] = confidences"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxpF_Axq-F34",
        "outputId": "d31a27dd-f039-4d21-9977-88dd5954fb18"
      },
      "source": [
        "!pip install scikit-learn\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(dataset_test[\"label_neg\"],labels_to_eval,digits=5))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.75570   0.98028   0.85346       710\n",
            "           1    0.78462   0.18478   0.29912       276\n",
            "\n",
            "    accuracy                        0.75761       986\n",
            "   macro avg    0.77016   0.58253   0.57629       986\n",
            "weighted avg    0.76379   0.75761   0.69829       986\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qFPdza90HcCF",
        "outputId": "62308bb3-82c4-4a54-e622-f71a3d86ac35"
      },
      "source": [
        "dataset_test"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>Giudizio</th>\n",
              "      <th>label_pos</th>\n",
              "      <th>label_neg</th>\n",
              "      <th>label_AlBERTo_pos</th>\n",
              "      <th>label_AlBERTo_neg</th>\n",
              "      <th>label_bin_ANN</th>\n",
              "      <th>label_bin_ALB</th>\n",
              "      <th>clean</th>\n",
              "      <th>predicted_label_neg</th>\n",
              "      <th>confidence_label_neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>@confagricoltura #Riso, procedura per ripristi...</td>\n",
              "      <td>procedura ripristino dazi rush finale regolame...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;user&gt; &lt;hashtag&gt; riso &lt;/hashtag&gt; procedura per...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>@GArancioni Gelate, xylella, sblocco Psr. A #B...</td>\n",
              "      <td>gelate xylella sblocco psr invasione video por...</td>\n",
              "      <td>Molto negativo</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;user&gt; gelate xylella sblocco psr a &lt;hashtag&gt; ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>@SocialConfeuro @GArancioni #GiletArancioni. P...</td>\n",
              "      <td>confeuro protesta giusta serve coerenza assunz...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>&lt;user&gt; &lt;user&gt; &lt;hashtag&gt; gilet arancio ni &lt;/has...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>@_Unaitalia Uova. Timbratura allorigine neces...</td>\n",
              "      <td>uova timbratura origine necessaria tutelare co...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;user&gt; uova timbratura all origine necessaria ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>@EUauditors  @giamma71 / Sicurezza alimentare ...</td>\n",
              "      <td>sicurezza alimentare sostanze chimiche sistema...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;user&gt; &lt;user&gt; / sicurezza alimentare e sostanz...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.730156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>995</td>\n",
              "      <td>996</td>\n",
              "      <td>My week on Twitter : 174 Mentions, 3.3M Menti...</td>\n",
              "      <td>my week on twitter mentions m mention reach li...</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>my week on twitter  &lt;number&gt; mentions &lt;number...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>996</td>\n",
              "      <td>997</td>\n",
              "      <td>#Tradizione torna protagonista a #tavola con a...</td>\n",
              "      <td>torna protagonista arrivo stime italiani spend...</td>\n",
              "      <td>Molto positivo</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;hashtag&gt; tradizione &lt;/hashtag&gt; torna protagon...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>997</td>\n",
              "      <td>998</td>\n",
              "      <td>Clima, Coldiretti: il Natale bollente con temp...</td>\n",
              "      <td>clima coldiretti natale bollente temperature a...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>clima coldiretti il natale bollente con temper...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.997625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>998</td>\n",
              "      <td>999</td>\n",
              "      <td>USA-UE, @masgiansanti: Possibili nuovi #dazi ...</td>\n",
              "      <td>usa ue possibili nuovi d oliva</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>usa ue &lt;user&gt; possibili nuovi &lt;hashtag&gt; dazi &lt;...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>999</td>\n",
              "      <td>1000</td>\n",
              "      <td>Capodanno, Coldiretti: le feste di fine anno f...</td>\n",
              "      <td>capodanno coldiretti feste fine anno registrar...</td>\n",
              "      <td>Molto positivo</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>capodanno coldiretti le feste di fine anno fan...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>986 rows  14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0    id  ... predicted_label_neg confidence_label_neg\n",
              "0             0     1  ...                   0             1.000000\n",
              "1             1     2  ...                   0             0.999828\n",
              "2             2     3  ...                   0             0.999959\n",
              "3             3     4  ...                   0             0.999982\n",
              "4             4     5  ...                   1             0.730156\n",
              "..          ...   ...  ...                 ...                  ...\n",
              "981         995   996  ...                   0             0.999963\n",
              "982         996   997  ...                   0             0.999999\n",
              "983         997   998  ...                   0             0.997625\n",
              "984         998   999  ...                   0             0.999999\n",
              "985         999  1000  ...                   0             1.000000\n",
              "\n",
              "[986 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l346o4qL7HK"
      },
      "source": [
        "m.save(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/models/model_1_neg_agritrend_0.57629.h5\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Pkf6QWMTTw"
      },
      "source": [
        "dataset_test.to_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/models/predictions_AGRITREND_neg_full.csv\");"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}