{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AGRITREND_WMAL_Model_5.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-sf82movkvc","outputId":"d9b58a13-57d5-4f21-c08f-6c9451dafed1"},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLlrzHzRv9XU"},"source":["import joblib\n","emb_matrix_train = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/sentipol_embedd_7410_128_768_alberto_training.joblib\")\n","wmal_matrix_train = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/dictionary_sentipolc_8266_training.joblib\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"se9351L01RCX"},"source":["import pandas as pd\n","dataset_DF = pd.read_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/data/sentipolc_train_processed.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2deOEjg1W_e","outputId":"829a3ada-1023-4ef8-cf87-dcdffd1aada3"},"source":["from sklearn.preprocessing import OneHotEncoder\n","from numpy import array\n","from numpy import argmax\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","# define example\n","data = dataset_DF[\"oneg\"]\n","values = array(data)\n","print(values)\n","# integer encode\n","label_encoder = LabelEncoder()\n","integer_encoded = label_encoder.fit_transform(values)\n","print(integer_encoded)\n","# binary encode\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","print(onehot_encoded)\n","# invert first example\n","inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n","print(inverted)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1 1 1 ... 1 0 0]\n","[1 1 1 ... 1 0 0]\n","[[0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," ...\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 0.]]\n","[1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Tc64TlXwys4","outputId":"6727e61d-9a2f-4725-f55d-ac1f118e3266"},"source":["from keras.layers import Input, Dense, LSTM, Bidirectional, TimeDistributed, Flatten, Concatenate, Dropout\n","!pip install keras-self-attention\n","from keras_self_attention import SeqWeightedAttention, SeqSelfAttention\n","from keras.layers import Add, Multiply"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.49.0)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.19.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-self-attention) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VEm3BOiY8EHn"},"source":["import joblib\n","import pandas as pd\n","emb_matrix_test = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/creagritrend_embedd_986_128_768_alberto.joblib\")\n","dataset_test = pd.read_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/data/creagritrend_processed.csv\")\n","wmal_matrix_test = joblib.load(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/support_files/dictionary_agritrend_8266.joblib\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ictcNZPP8TWc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca9d2dea-bfcd-445a-bf68-dd728c10a314"},"source":["# define example\n","data = dataset_test[\"label_neg\"]\n","values = array(data)\n","print(values)\n","# integer encode\n","integer_encoded_test = label_encoder.transform(values)\n","print(integer_encoded_test)\n","# binary encode\n","integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n","onehot_encoded_test = onehot_encoder.transform(integer_encoded_test)\n","print(onehot_encoded_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0\n"," 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0\n"," 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n"," 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n"," 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0\n"," 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n"," 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1\n"," 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n"," 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0\n"," 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n"," 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0\n"," 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1\n"," 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0\n"," 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n"," 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0\n"," 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n"," 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0\n"," 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0\n"," 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0\n"," 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0\n"," 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0\n"," 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0\n"," 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0\n"," 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1\n"," 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0]\n","[0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0\n"," 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0\n"," 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n"," 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n"," 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0\n"," 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n"," 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1\n"," 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n"," 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0\n"," 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n"," 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0\n"," 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1\n"," 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0\n"," 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n"," 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0\n"," 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n"," 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0\n"," 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0\n"," 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0\n"," 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0\n"," 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0\n"," 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0\n"," 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0\n"," 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1\n"," 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0]\n","[[1. 0.]\n"," [0. 1.]\n"," [0. 1.]\n"," ...\n"," [0. 1.]\n"," [0. 1.]\n"," [1. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HaSsX9AewjPU"},"source":["import keras\n","from sklearn.metrics import precision_recall_fscore_support as score\n","import numpy as np\n","\n","input_emb = Input(shape=(128,768))\n","input_wmal = Input(shape=(8266,))\n","\n","#Bi-LSTM\n","#bi = Bidirectional(LSTM(64, return_sequences=True))(input_emb)\n","bi = LSTM(64, return_sequences=True)(input_emb)\n","att = SeqSelfAttention(attention_width=15,attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n","                       attention_activation=\"sigmoid\",\n","                       kernel_regularizer=keras.regularizers.l2(1e-8),#(1e-6),\n","                       bias_regularizer=keras.regularizers.l1(1e-4),#(1e-4),\n","                       attention_regularizer_weight=1e-8,#1e-4,\n","                       use_attention_bias=True) (bi)\n","\n","app = Add() ([bi, att])                      \n","flat = Flatten()(app)\n","den1 = Dense(4000) (flat)\n","den2 = Dense(2000) (den1)\n","den3 = Dense(1000) (den2)\n","den4 = Dense(500) (den3)\n","den5 = Dense(256) (den4)\n","den6 = Dense(128) (den5)\n","den7 = Dense(64) (den6)\n","\n","#WMAL \n","d0 = Dense(1000) (input_wmal)\n","\n","#Concat\n","concat = Concatenate(axis=1)([den7, d0])\n","final_dense = Dense(32, activation=\"relu\") (concat)\n","output = Dense(2,activation=\"softmax\") (final_dense)\n","\n","m = keras.Model(inputs=[input_emb,input_wmal], outputs=output)\n","\n","opt = keras.optimizers.RMSprop()\n","\n","m.compile(loss=\"categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n","\n","class myCallback(keras.callbacks.Callback):\n","    bestF1=0\n","    def __init__(self):\n","        super().__init__()\n","        self._get_pred = None\n","        self.preds = []\n","    def on_epoch_end(self,epoch, logs=None):\n","        predictions = m.predict([emb_matrix_test,wmal_matrix_test])\n","        predictions_vec = np.zeros((986,4))\n","        i = 0\n","        confidences= []\n","        for item in predictions:\n","          index = np.argmax(item);\n","          confidences.append(item[index])\n","          predictions_vec[i][index] = 1\n","          i = i+1\n","        labels_to_eval = []\n","        for vec in predictions_vec:\n","          inverted = label_encoder.inverse_transform([argmax(vec)])[0]\n","          labels_to_eval.append(inverted)\n","        \n","        precision,recall,fscore,support=score(dataset_test[\"label_neg\"],labels_to_eval,average='macro')\n","        print(\"Test f1-score:\"+str(fscore))\n","        if fscore > self.bestF1:\n","          m.save(\"bestModel.h5\")\n","          print(\"BEST MODEL!!!!!\")\n","          self.bestF1 = fscore\n","\n","callbacks = [myCallback()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j8V5UduPAvTH"},"source":["m.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c__iZWCz32Tv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"53391019-55a3-410a-81bb-d33fb3644ff4"},"source":["m.fit([emb_matrix_train,wmal_matrix_train],onehot_encoded,batch_size=128, epochs=100,validation_split=0.15, callbacks=[callbacks])\n","#m.load_weights(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/models/model_3_sentipolc/model_3_neg_sentipolc_0.72803.h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","50/50 [==============================] - 7s 92ms/step - loss: 71.2069 - accuracy: 0.5113 - val_loss: 0.4863 - val_accuracy: 0.8085\n","Test f1-score:0.4340693219983207\n","BEST MODEL!!!!!\n","Epoch 2/100\n","50/50 [==============================] - 4s 81ms/step - loss: 0.6351 - accuracy: 0.6846 - val_loss: 0.5778 - val_accuracy: 0.7338\n","Test f1-score:0.5180750302198456\n","BEST MODEL!!!!!\n","Epoch 3/100\n","50/50 [==============================] - 4s 73ms/step - loss: 1.4287 - accuracy: 0.6486 - val_loss: 0.5635 - val_accuracy: 0.8058\n","Test f1-score:0.4741431167172083\n","Epoch 4/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.9270 - accuracy: 0.6565 - val_loss: 0.6050 - val_accuracy: 0.7941\n","Test f1-score:0.4873620220764678\n","Epoch 5/100\n","50/50 [==============================] - 4s 72ms/step - loss: 0.5274 - accuracy: 0.7370 - val_loss: 0.5873 - val_accuracy: 0.8210\n","Test f1-score:0.5604057608015027\n","BEST MODEL!!!!!\n","Epoch 6/100\n","50/50 [==============================] - 4s 75ms/step - loss: 0.5776 - accuracy: 0.7283 - val_loss: 2.0437 - val_accuracy: 0.5432\n","Test f1-score:0.4029416240325331\n","Epoch 7/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.6179 - accuracy: 0.7644 - val_loss: 5.4537 - val_accuracy: 0.5522\n","Test f1-score:0.6292346084162308\n","BEST MODEL!!!!!\n","Epoch 8/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.6294 - accuracy: 0.8089 - val_loss: 0.6687 - val_accuracy: 0.7761\n","Test f1-score:0.5449930779880018\n","Epoch 9/100\n","50/50 [==============================] - 4s 72ms/step - loss: 0.4210 - accuracy: 0.8415 - val_loss: 1.0116 - val_accuracy: 0.6978\n","Test f1-score:0.618388234282274\n","Epoch 10/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.2469 - accuracy: 0.9035 - val_loss: 1.2244 - val_accuracy: 0.7176\n","Test f1-score:0.630707184505582\n","BEST MODEL!!!!!\n","Epoch 11/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.1979 - accuracy: 0.9241 - val_loss: 1.0630 - val_accuracy: 0.7995\n","Test f1-score:0.5410892310852062\n","Epoch 12/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0985 - accuracy: 0.9635 - val_loss: 2.0133 - val_accuracy: 0.6349\n","Test f1-score:0.6601620148690974\n","BEST MODEL!!!!!\n","Epoch 13/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0988 - accuracy: 0.9707 - val_loss: 1.3754 - val_accuracy: 0.7788\n","Test f1-score:0.5512194641029138\n","Epoch 14/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.2149 - accuracy: 0.9477 - val_loss: 1.6130 - val_accuracy: 0.7869\n","Test f1-score:0.5681444454316046\n","Epoch 15/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.1540 - accuracy: 0.9703 - val_loss: 1.6879 - val_accuracy: 0.7752\n","Test f1-score:0.5526369406249626\n","Epoch 16/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.2052 - accuracy: 0.9474 - val_loss: 2.3925 - val_accuracy: 0.7806\n","Test f1-score:0.5648338901927419\n","Epoch 17/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0975 - accuracy: 0.9711 - val_loss: 2.3371 - val_accuracy: 0.7473\n","Test f1-score:0.5892950119754243\n","Epoch 18/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0589 - accuracy: 0.9827 - val_loss: 1.7001 - val_accuracy: 0.7230\n","Test f1-score:0.5687153794976789\n","Epoch 19/100\n","50/50 [==============================] - 4s 75ms/step - loss: 0.1284 - accuracy: 0.9681 - val_loss: 2.0064 - val_accuracy: 0.7473\n","Test f1-score:0.6014131046119235\n","Epoch 20/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0438 - accuracy: 0.9847 - val_loss: 2.0322 - val_accuracy: 0.7941\n","Test f1-score:0.5364179414719609\n","Epoch 21/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.4130 - accuracy: 0.9511 - val_loss: 2.0392 - val_accuracy: 0.7653\n","Test f1-score:0.5586968879247822\n","Epoch 22/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0311 - accuracy: 0.9928 - val_loss: 1.9854 - val_accuracy: 0.7653\n","Test f1-score:0.5951612547184388\n","Epoch 23/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0315 - accuracy: 0.9929 - val_loss: 2.0200 - val_accuracy: 0.7635\n","Test f1-score:0.593196751091488\n","Epoch 24/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0239 - accuracy: 0.9949 - val_loss: 2.4154 - val_accuracy: 0.6799\n","Test f1-score:0.590460822548216\n","Epoch 25/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 2.5693 - val_accuracy: 0.7428\n","Test f1-score:0.5887775889040624\n","Epoch 26/100\n","50/50 [==============================] - 4s 78ms/step - loss: 0.0338 - accuracy: 0.9919 - val_loss: 2.3047 - val_accuracy: 0.7419\n","Test f1-score:0.5719458351037299\n","Epoch 27/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0174 - accuracy: 0.9966 - val_loss: 2.1586 - val_accuracy: 0.7968\n","Test f1-score:0.5471575883857307\n","Epoch 28/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 2.8794 - val_accuracy: 0.7914\n","Test f1-score:0.595255074218118\n","Epoch 29/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 3.2998 - val_accuracy: 0.7860\n","Test f1-score:0.5494307711850286\n","Epoch 30/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0296 - accuracy: 0.9932 - val_loss: 2.5546 - val_accuracy: 0.7536\n","Test f1-score:0.5983980354606463\n","Epoch 31/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0404 - accuracy: 0.9909 - val_loss: 3.7287 - val_accuracy: 0.6844\n","Test f1-score:0.6232800355899826\n","Epoch 32/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0289 - accuracy: 0.9948 - val_loss: 2.9773 - val_accuracy: 0.7131\n","Test f1-score:0.6301715564233354\n","Epoch 33/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0370 - accuracy: 0.9924 - val_loss: 1.5397 - val_accuracy: 0.8219\n","Test f1-score:0.5086393260917756\n","Epoch 34/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.1423 - accuracy: 0.9723 - val_loss: 2.0198 - val_accuracy: 0.7725\n","Test f1-score:0.5804833615983412\n","Epoch 35/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 2.1897 - val_accuracy: 0.7869\n","Test f1-score:0.584206185311281\n","Epoch 36/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0175 - accuracy: 0.9954 - val_loss: 3.7987 - val_accuracy: 0.7662\n","Test f1-score:0.6100267868378946\n","Epoch 37/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0508 - accuracy: 0.9892 - val_loss: 12.2345 - val_accuracy: 0.5809\n","Test f1-score:0.6367834681042228\n","Epoch 38/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.1246 - accuracy: 0.9875 - val_loss: 2.0699 - val_accuracy: 0.7833\n","Test f1-score:0.5700432156617723\n","Epoch 39/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 5.6742 - val_accuracy: 0.7842\n","Test f1-score:0.6184687377196536\n","Epoch 40/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.6538 - accuracy: 0.9584 - val_loss: 2.8235 - val_accuracy: 0.7545\n","Test f1-score:0.5925496938436944\n","Epoch 41/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0225 - accuracy: 0.9961 - val_loss: 3.4589 - val_accuracy: 0.7833\n","Test f1-score:0.5700564505674519\n","Epoch 42/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 3.3914 - val_accuracy: 0.7491\n","Test f1-score:0.6192800357738616\n","Epoch 43/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 3.8955 - val_accuracy: 0.7680\n","Test f1-score:0.5989976910159531\n","Epoch 44/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0250 - accuracy: 0.9937 - val_loss: 3.4530 - val_accuracy: 0.7797\n","Test f1-score:0.5909087939156741\n","Epoch 45/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 4.4084 - val_accuracy: 0.7842\n","Test f1-score:0.5908397830576518\n","Epoch 46/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.2521 - accuracy: 0.9732 - val_loss: 3.5229 - val_accuracy: 0.7419\n","Test f1-score:0.6057659932659933\n","Epoch 47/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 3.8931 - val_accuracy: 0.7869\n","Test f1-score:0.5729767257339329\n","Epoch 48/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0173 - accuracy: 0.9984 - val_loss: 3.7956 - val_accuracy: 0.7959\n","Test f1-score:0.5522659159022796\n","Epoch 49/100\n","50/50 [==============================] - 4s 72ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 4.0475 - val_accuracy: 0.7662\n","Test f1-score:0.6112286935358873\n","Epoch 50/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0918 - accuracy: 0.9890 - val_loss: 3.9704 - val_accuracy: 0.7572\n","Test f1-score:0.6252974625411049\n","Epoch 51/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0182 - accuracy: 0.9965 - val_loss: 3.2541 - val_accuracy: 0.7077\n","Test f1-score:0.59487880636363\n","Epoch 52/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 5.6724 - val_accuracy: 0.7653\n","Test f1-score:0.6227602770330652\n","Epoch 53/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0543 - accuracy: 0.9915 - val_loss: 3.5278 - val_accuracy: 0.7833\n","Test f1-score:0.6011637592660286\n","Epoch 54/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0301 - accuracy: 0.9970 - val_loss: 4.3800 - val_accuracy: 0.7806\n","Test f1-score:0.5938654781079713\n","Epoch 55/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0435 - accuracy: 0.9907 - val_loss: 3.8832 - val_accuracy: 0.7860\n","Test f1-score:0.5859706506364922\n","Epoch 56/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 5.3078 - val_accuracy: 0.7527\n","Test f1-score:0.6283033992677167\n","Epoch 57/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0255 - accuracy: 0.9963 - val_loss: 4.9916 - val_accuracy: 0.7149\n","Test f1-score:0.623895854789579\n","Epoch 58/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0408 - accuracy: 0.9935 - val_loss: 3.9091 - val_accuracy: 0.7689\n","Test f1-score:0.6134055265123226\n","Epoch 59/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 5.0614 - val_accuracy: 0.7833\n","Test f1-score:0.5923027989821883\n","Epoch 60/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.4589 - accuracy: 0.9791 - val_loss: 7.0963 - val_accuracy: 0.7653\n","Test f1-score:0.6217602233592727\n","Epoch 61/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0218 - accuracy: 0.9957 - val_loss: 3.7649 - val_accuracy: 0.7734\n","Test f1-score:0.6028018278018278\n","Epoch 62/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 3.9870 - val_accuracy: 0.7797\n","Test f1-score:0.5905882352941176\n","Epoch 63/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.2328 - accuracy: 0.9728 - val_loss: 5.1130 - val_accuracy: 0.7500\n","Test f1-score:0.598160223567769\n","Epoch 64/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.1239 - accuracy: 0.9875 - val_loss: 4.2090 - val_accuracy: 0.7536\n","Test f1-score:0.6335361730899256\n","Epoch 65/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 4.9088 - val_accuracy: 0.7986\n","Test f1-score:0.5820860135079174\n","Epoch 66/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0852 - accuracy: 0.9890 - val_loss: 4.0613 - val_accuracy: 0.7905\n","Test f1-score:0.583230638257339\n","Epoch 67/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0341 - accuracy: 0.9965 - val_loss: 4.7714 - val_accuracy: 0.7041\n","Test f1-score:0.6114708006422527\n","Epoch 68/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0292 - accuracy: 0.9932 - val_loss: 3.6029 - val_accuracy: 0.7806\n","Test f1-score:0.6114118219381377\n","Epoch 69/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0184 - accuracy: 0.9979 - val_loss: 3.2583 - val_accuracy: 0.7626\n","Test f1-score:0.6037993946958946\n","Epoch 70/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 4.0097 - val_accuracy: 0.8085\n","Test f1-score:0.5797210023249806\n","Epoch 71/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.9376 - accuracy: 0.9737 - val_loss: 3.9491 - val_accuracy: 0.7581\n","Test f1-score:0.6105712402254955\n","Epoch 72/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0353 - accuracy: 0.9916 - val_loss: 3.3412 - val_accuracy: 0.7671\n","Test f1-score:0.6194331748823225\n","Epoch 73/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 11.7269 - val_accuracy: 0.6871\n","Test f1-score:0.6621301623833269\n","BEST MODEL!!!!!\n","Epoch 74/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.1315 - accuracy: 0.9833 - val_loss: 2.8464 - val_accuracy: 0.7761\n","Test f1-score:0.6310556876542014\n","Epoch 75/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0312 - accuracy: 0.9935 - val_loss: 3.3772 - val_accuracy: 0.7779\n","Test f1-score:0.6322461328938103\n","Epoch 76/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0159 - accuracy: 0.9986 - val_loss: 3.0708 - val_accuracy: 0.7815\n","Test f1-score:0.6222363017017121\n","Epoch 77/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 3.4195 - val_accuracy: 0.7635\n","Test f1-score:0.6237319249205924\n","Epoch 78/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0441 - accuracy: 0.9943 - val_loss: 5.3952 - val_accuracy: 0.7473\n","Test f1-score:0.6368354297171405\n","Epoch 79/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0326 - accuracy: 0.9948 - val_loss: 2.4612 - val_accuracy: 0.7725\n","Test f1-score:0.5843473873586796\n","Epoch 80/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 2.8308 - val_accuracy: 0.7977\n","Test f1-score:0.6217510759209588\n","Epoch 81/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0513 - accuracy: 0.9922 - val_loss: 2.7256 - val_accuracy: 0.7788\n","Test f1-score:0.622289679759839\n","Epoch 82/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0350 - accuracy: 0.9933 - val_loss: 7.2878 - val_accuracy: 0.7743\n","Test f1-score:0.6137419601698159\n","Epoch 83/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0247 - accuracy: 0.9958 - val_loss: 3.9711 - val_accuracy: 0.7554\n","Test f1-score:0.6310556876542014\n","Epoch 84/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 5.1951 - val_accuracy: 0.7464\n","Test f1-score:0.6532026518914225\n","Epoch 85/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.0054 - accuracy: 0.9977 - val_loss: 4.9264 - val_accuracy: 0.7581\n","Test f1-score:0.6433585739657812\n","Epoch 86/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0797 - accuracy: 0.9972 - val_loss: 4.3391 - val_accuracy: 0.7329\n","Test f1-score:0.626768361581921\n","Epoch 87/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 3.8785 - val_accuracy: 0.8013\n","Test f1-score:0.5990544829410209\n","Epoch 88/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 4.8625 - val_accuracy: 0.7806\n","Test f1-score:0.6127638684339716\n","Epoch 89/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0301 - accuracy: 0.9955 - val_loss: 4.3343 - val_accuracy: 0.7914\n","Test f1-score:0.6120171137690891\n","Epoch 90/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0291 - accuracy: 0.9953 - val_loss: 5.2470 - val_accuracy: 0.8004\n","Test f1-score:0.6094368919732547\n","Epoch 91/100\n","50/50 [==============================] - 4s 73ms/step - loss: 0.8447 - accuracy: 0.9888 - val_loss: 6.0692 - val_accuracy: 0.7509\n","Test f1-score:0.6276054510635084\n","Epoch 92/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 3.3331 - val_accuracy: 0.7806\n","Test f1-score:0.608249603064898\n","Epoch 93/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 6.5053 - val_accuracy: 0.7788\n","Test f1-score:0.6008863900084289\n","Epoch 94/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0155 - accuracy: 0.9980 - val_loss: 4.5422 - val_accuracy: 0.7860\n","Test f1-score:0.5835507257178918\n","Epoch 95/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 3.5308 - val_accuracy: 0.8138\n","Test f1-score:0.5780997763298649\n","Epoch 96/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 3.5856 - val_accuracy: 0.7815\n","Test f1-score:0.5903208002331739\n","Epoch 97/100\n","50/50 [==============================] - 4s 78ms/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 5.5069 - val_accuracy: 0.7896\n","Test f1-score:0.5859706506364922\n","Epoch 98/100\n","50/50 [==============================] - 4s 75ms/step - loss: 0.0289 - accuracy: 0.9944 - val_loss: 6.0606 - val_accuracy: 0.7905\n","Test f1-score:0.6089045302165027\n","Epoch 99/100\n","50/50 [==============================] - 4s 75ms/step - loss: 0.0259 - accuracy: 0.9964 - val_loss: 4.9774 - val_accuracy: 0.7716\n","Test f1-score:0.6276054510635084\n","Epoch 100/100\n","50/50 [==============================] - 4s 74ms/step - loss: 0.0101 - accuracy: 0.9987 - val_loss: 4.8373 - val_accuracy: 0.7995\n","Test f1-score:0.6240047414050547\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff1fb267128>"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"rnGfTDKQ8tFG"},"source":["m.load_weights(\"bestModel.h5\")\n","predictions = m.predict([emb_matrix_test,wmal_matrix_test])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lC7taZDs9Y-_"},"source":["import numpy as np\n","predictions_vec = np.zeros((986,4))\n","i = 0\n","confidences= []\n","for item in predictions:\n","  index = np.argmax(item);\n","  confidences.append(item[index])\n","  predictions_vec[i][index] = 1\n","  i = i+1\n","labels_to_eval = []\n","for vec in predictions_vec:\n","  inverted = label_encoder.inverse_transform([argmax(vec)])[0]\n","  labels_to_eval.append(inverted)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxpF_Axq-F34","outputId":"8683eeb8-2f6b-4a36-8d44-bf3852f4f3bf"},"source":["!pip install scikit-learn\n","\n","from sklearn.metrics import classification_report\n","print(classification_report(dataset_test[\"label_neg\"],labels_to_eval,digits=5))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.4)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n","              precision    recall  f1-score   support\n","\n","           0    0.81039   0.81268   0.81153       710\n","           1    0.51460   0.51087   0.51273       276\n","\n","    accuracy                        0.72819       986\n","   macro avg    0.66250   0.66177   0.66213       986\n","weighted avg    0.72759   0.72819   0.72789       986\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7l346o4qL7HK"},"source":["m.save(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/models/model_new_neg_agritrend_0.67343.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_Pkf6QWMTTw"},"source":["dataset_test.to_csv(\"/content/drive/MyDrive/SI_AI_KBS/integrazione_AlBERTo_WMAL/sentipolc_agritrend/models/predictions_AGRITREND_neg_full_0.67343.csv\");"],"execution_count":null,"outputs":[]}]}